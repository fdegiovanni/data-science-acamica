{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEFRqVgwU4TH"
   },
   "source": [
    "# Probabilidad y Estadística\n",
    "\n",
    "El objetivo del siguiente notebook es afianzar algunos conceptos de Probabilidad y, de paso, empezar a ver cómo se hacen gráficos con Matplotlib, una nueva librería que veremos más en detalle en la próxima bitácora y encuentro. Por ahora, solamente tienen que instalarla y correr las celdas. ¡No te preocupes si no entiendes lo que hacen esas celdas! Lo importante es que prestes atención a sus resultados.\n",
    "\n",
    "## 1. Distribuciones de probabilidad\n",
    "\n",
    "El concepto de distribución de probabilidad es un concepto central en probabilidad y estadística y, por lo tanto, hay mucho para decir. Nos limitamos acá a los puntos más importantes.\n",
    "\n",
    "\n",
    "### 1.1 Distrubución Uniforme Discreta\n",
    "\n",
    "Comencemos por un ejemplo: un dado de seis caras. La probabilidad de que al tirar el dado *salga* una cara es $1/6$. Si graficamos la probabilidad para cada resultado posible de tirar un dado, obtendríamos un gráfico como el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-fHqWnzU4TR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSbq4R-aU4Tt"
   },
   "outputs": [],
   "source": [
    "valores = np.arange(1,7)\n",
    "probas = np.zeros(6) + 1/6\n",
    "plt.bar(valores, probas)\n",
    "plt.title('Distribución de probabilidad uniforme: lanzamiento de un dado')\n",
    "# plt.savefig('distribucion_dado.png', dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hl-vXlaCU4T_"
   },
   "source": [
    "En este caso, decimos que la distribución de probabilidad es *uniforme discreta*, ya que le asigna la misma probabilidad a los seis valores que pueden salir al tirar el dado. Si el dado estuviera cargado, ya no sería uniforme.\n",
    "\n",
    "**Algunos detalles**:\n",
    "1. El resultado de tirar un dado es un ejemplo de una *variable aleatoria*.\n",
    "2. En el caso del dado, la variable aleatoria puede tomar valores *discretos* y *acotados* (limitados): 1, 2, 3, 4, 5 y 6\n",
    "3. Existen variables aleatorias donde los posibles valores que puede tomar son continuos y no acotados. Veremos la distribución más famosa de ellas a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIXL9A1yU4UE"
   },
   "source": [
    "### 1.2 Distribución Normal o Gaussiana\n",
    "\n",
    "La distribución normal o gaussiana debe ser la distribución más famosa dentro de las distribuciones. Es una distribución de variable continua y aparece en una infinidad de ámbitos de la ciencia. Muchas variables asociadas a fenómenos naturales siguen una distribución gaussiana; un ejemplo típico es la estatura de las personas. La forma que tiene esta distribución está dada por la siguiente fórmula:\n",
    "\n",
    "$$f(x|\\mu, \\sigma^2)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{\\frac{-(x - \\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "¡No te asustes si no la entiendes! Durante el encuentro, veremos más en detalle algunos aspectos de esta distribución. Pero es importante resaltar que tiene sólo dos parámetros: su valor medio $\\mu$ y su desviacíon estándar $\\sigma$. Estos valores son *teóricos*, es decir, son propios de la distribución de probabilidad. \n",
    "\n",
    "Recomendamos entrar en la página de Wikipedia de la [Distribución Normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal) y prestar atención al primer gráfico - dónde podrán ver la forma teórica de la distribución - y a la sección \"Propiedades\".\n",
    "\n",
    "\n",
    "**Distribución Normal en NumPy**\n",
    "\n",
    "Como mencionamos en el encuentro anterior, NumPy nos provee de herramientas para generar valores aleatorios de distribuciones. A continuación generamos, usando `np.random.normal()`, muestras de dos distribuciones normales, con el mismo valor medio pero distinta desviación estándar. **Consultar** la ayuda de la función para entender bien qué hace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnQ6ZwhAU4UJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = 2.0\n",
    "sigma_1 = 5.0\n",
    "sigma_2 = 2.0\n",
    "muestras_1 = np.random.normal(loc = mu, scale = sigma_1, size = 400)\n",
    "muestras_2 = np.random.normal(loc = mu, scale = sigma_2, size = 400)\n",
    "print(muestras_1, muestras_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHFxZhG0U4Ub"
   },
   "source": [
    "Notar que son dos \"tiras\" de números, bastante largas y que a simple vista no nos dicen mucho. Mejor, podemos graficar su histograma. Veremos bien qué es un histograma en la próxima bitácora. Por ahora, basta saber que es una forma de visualizar cómo está distribuida una tira de números. Lo que hace es tomar un número determinado de intervalos (`bins = 20`) y contar cuántas muestras caen en cada intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nu_9GbwU4Uf"
   },
   "outputs": [],
   "source": [
    "plt.hist(muestras_1, bins = 20, alpha = 0.5, label = 'Histrograma Muestra 1')\n",
    "plt.hist(muestras_2, bins = 20, alpha = 0.5, label = 'Histrograma Muestra 2')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ez12LcZU4Uu"
   },
   "source": [
    "**Ejercicio:** Volver a \"generar\" las muestas y hacer sus histogramas. ¿Cambió?¿Por qué? Googlear que es una *semilla* (`seed`) en NumPy e implementar. También, cambiar la cantidad de muestras, modificando el argumento `size`. \n",
    "\n",
    "### 1.3 Relación entre Probabilidad y Estadística\n",
    "\n",
    "**Promedio y desviación estándar en una distribución Normal**\n",
    "\n",
    "En una distribución normal, el promedio de las muestras obtenidas *tiende* al valor medio $\\mu$ de la distribución, y la desviación estándar *tiende* a la desviacíon estándar $\\sigma$ de la distribución. Notar, entonces, que existen valores calculados (promedio, desviación estándar) y valores teóricos ($\\mu$ y $\\sigma$). Confundirlos entre sí es un error común.\n",
    "\n",
    "Veamos un ejemplo. Nuevamente, obtenemos muestras de una distribución normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55UHxgsWU4Uy"
   },
   "outputs": [],
   "source": [
    "mu = 8.5\n",
    "sigma = 3.0\n",
    "muestras = np.random.normal(loc = mu, scale = sigma, size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrLpnkqqU4U9"
   },
   "source": [
    "Y calculamos su promedio y desviación estándar, y comparamos con $\\mu$ y $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1JKKz5eU4VC"
   },
   "outputs": [],
   "source": [
    "print('Valor medio teorico:', mu, '. Valor medio calculado:', muestras.mean())\n",
    "print('Desviacion estandar teorica:', sigma, '. Desviacion estandar calculada:', muestras.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqQs6D_YU4VQ"
   },
   "source": [
    "Comparemos el histograma de las muestras y la distribución teórica, que graficaremos haciendo uso de la librería `SciPy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf31AbLMU4VU"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.hist(muestras, bins=20, density=True, alpha=0.6, color='g')\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2, label = 'Distribución Teórica')\n",
    "\n",
    "title = \"Muestras obtenidas de una distribución normal con mu = %.2f,  sigma = %.2f\" % (mu, sigma)\n",
    "\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTOjCCEQU4Vi"
   },
   "source": [
    "**Nota:** si estás atento/a a la escala en el eje *y*, notarás que es distinta a la escala de los histogramas anteriores. Esto se debe a que, en un histograma, además de graficar la cantidad de muestras que entran en cada intervalo, podemos también graficar la **proporción** de muestras que entran en cada intervalo.\n",
    "\n",
    "**Para pensar y probar:** \n",
    "1. ¿Por qué no coinciden $\\mu$ y $\\sigma$ con los valores calculados?¿Qué podemos hacer para que se parezcan cada vez más?¿Y qué ocurre en ese caso con el histograma y la distribución teórica?\n",
    "2. Con respecto al ejercicio que acabamos de hacer, ¿cuáles son los *parámetros* asociados al mundo de las probabilidades y cuáles son los *valores estadísticos* asociados al mundo de la estadística?\n",
    "\n",
    "\n",
    "### Ejercitación\n",
    " \n",
    "Los siguientes ejercicios pueden parecer muy difíciles, pero te aseguramos que no lo son tanto. ¡Lo importante es que los intentes!\n",
    "\n",
    "**Ejercicio 1 - Challenge:** Muchos juegos de mesa requieren tirar dados y sumar sus resultados. Por ejemplo, el [Catán](https://es.wikipedia.org/wiki/Los_Colonos_de_Cat%C3%A1n). Es evidente que, mientras en un dado la probabilidad de que salga cada cara es la misma, en esta variable aleatoria todos los resultados no son igual de probables (¿Cuáles son los posibles resultados?). Entonces, para mejorar tu estrategia en estos juegos, es útil saber cuál es la probabilidad asociada a cada resultado. Para ello, debes calcular su distribución de probabilidad. Entonces, \n",
    "\n",
    "Obtener la distribución de la variable aleatoria *suma del resultado de tirar dos dados*. Para ello puedes intentar alguna o ambas de las siguientes opciones:\n",
    "1. **Obtener la distribución teórica:** para ello, basta contar los casos *a mano* con lápiz y papel. Por ejemplo:\n",
    "    1. Uno (1) es un resultado imposible\n",
    "    2. Dos (2) solamente puede ser obtenida con ambos dados en 1, 1 + 1\n",
    "    3. Tres (3) tiene dos opciones, 2 + 1 y 1 + 2\n",
    "    4. Cuatro (4) tiene tres opciones: 3 + 1, 2 + 2, 1 + 3\n",
    "    \n",
    "    y así para el resto de los posibles resultados. Completa la lista hasta el 12 y cuenta cuántas combinaciones existen para cada resultado. ¿Cuántos combinaciones debe haber en total, teniendo en cuenta que cada dado tiene seis caras? Al final, debes llevarlos a porcentaje. Por ejemplo, si en total son 100 posibles combinaciones, y el 12 tiene 10 posibles combinaciones, su probabilidad es 10/100 = 0.1\n",
    "    \n",
    "2. **Simular y obtener una distribución aproximada:** otra opción es simular esta situación. Viste en el notebook de la bitácora anterior cómo simular un dado. Ahora simula dos dados y obtiene la suma de sus resultados.\n",
    "\n",
    "¿Te animas a comparar ambos métodos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "327V3n7oU4Vm"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR: UNA LINEA DE CODIGO \n",
    "# COMPLETAR: OTRA LINEA DE CODIGO \n",
    "\n",
    "suma = # COMPLETAR\n",
    "\n",
    "plt.hist(suma, bins = np.arange(1.5,13.5,1), density=True, rwidth = 0.8,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkNiPekCU4V0"
   },
   "source": [
    "**Ejercicio 2:** Obtiene, simulando, la distribución de la variable aleatoria *máximo valor obtenido al tirar dos dados.* Por ejemplo, si obtenemos 2 y 5, el resultado es 5. Nuevamente, si lo deseas, también puedes contar casos y obtener la distribución teórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzyvWre3U4V4"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR: UNA LINEA DE CODIGO \n",
    "# COMPLETAR: OTRA LINEA DE CODIGO \n",
    "\n",
    "'''Combinamos las muestras obtenidas en un arreglo de dos filas, donde\n",
    "cada columna corresponde a una tirada'''\n",
    "muestras = np.array([COMPLETAR,COMPLETAR])\n",
    "print(muestras.shape)\n",
    "\n",
    "\n",
    "'''Obtenemos el máximo de cada tirada. Recordar obtener el máximo\n",
    "en el eje (axis) correspondiente'''\n",
    "maximos = np.max(COMPLETAR, axis = COMPLETAR)\n",
    "\n",
    "plt.hist(COMPLETAR, bins = np.arange(0.5,7.5,1), density=True, rwidth = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu_y4bliU4WK"
   },
   "source": [
    "## 2. Correlación\n",
    "\n",
    "El objetivo de esta sección es que te familiarices con los conceptos de **Covarianza** y **Correlación**. Si bien las fórmulas parecen difíciles, esperemos que veas que nada es tan grave como parece. También que prestes atención a cómo a veces es útil simular datos para aprender o acercarse a algunas técnicas.\n",
    "\n",
    "Tenemos dos variables aleatorias $X$ e $Y$, de las cuales tenemos $n$ muestras de cada una, $x_1,x_2,..., x_n$ e $y_1,y_2,..., y_n$. Sus valores medios son $\\bar{x}$ e $\\bar{y}$, respectivamente. Definimos la Covarianza como\n",
    "\n",
    "$$Cov(X,Y) = \\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})(y_i - \\bar{y})}{n}$$\n",
    "\n",
    "A veces verás que, en lugar de dividir por $n$, se divide por $n - 1$ ó $n - 2$, pero eso no es importante ahora. Según Wikipedia, \"la covarianza es un valor que indica el grado de variación conjunta de dos variables aleatorias respecto a sus medias. Es el dato básico para determinar si existe una dependencia entre ambas variables y además es el dato necesario para estimar otros parámetros básicos, como el coeficiente de correlación lineal o la recta de regresión.\". \n",
    "\n",
    "Si bien la fórmula puede parecer difícil, veamos qué nos dice de nuestros datos simulando algunos casos sencillos.\n",
    "\n",
    "Empezamos generandos muestras al azar de dos variables aleatorias no relacionadas entre sí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q66jDC_IU4WO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWwL1LZ7U4Wa"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "sigma_1 = 2\n",
    "sigma_2 = 20\n",
    "x = np.random.normal(size = n, scale = sigma_1)\n",
    "y = np.random.normal(size = n, scale = sigma_2)\n",
    "\n",
    "# Graficamos\n",
    "plt.scatter(x, y)\n",
    "plt.grid()\n",
    "plt.xlim([-60,60])\n",
    "plt.ylim([-60,60])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w44BW3CCU4Wl"
   },
   "source": [
    "¿Hay alguna relación entre ellos? Por relación nos referimos a \"variación conjunta\". Y por \"variación conjunta\" podemos imaginarnos que si una de las variables aumenta, la otra también lo hace. Y si una variable disminuye su valor, la otra también lo hace. La covarianza intenta cuantificar esa relación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wX-H3y-U4Wo"
   },
   "outputs": [],
   "source": [
    "cov = np.sum((x - x.mean())*(y - y.mean()))/x.size\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzbRb7kmU4W0"
   },
   "source": [
    "La covarianza, sin embargo, tiene un pequeño problema: depende de la escala de nuestros datos. Entonces, para deshacernos de la escala, se puede definir la Correlación, que no es otra cosa que la covarianza dividida la desviación estándar de cada variable aletaria.\n",
    "\n",
    "$$Corr(X,Y) = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wW2-EG20U4W2"
   },
   "outputs": [],
   "source": [
    "corr = cov/(x.std()*y.std())\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHClidVeU4XC"
   },
   "source": [
    "Y con eso nos deshacemos de la escala. Un valor cercano a cero nos indica que no existe una relación (¿lineal?) entre las variables.\n",
    "\n",
    "**Probar** con distintas escalas (modificando `sigma_1` y `sigma_2`) y verán que `cov` tomará valores en un rango muy amplio, mientras que `corr` se mantendrá cercana a cero.\n",
    "\n",
    "### 2.1 Relación lineal\n",
    "\n",
    "Veamos otro ejemplo: sabemos que existe una relación lineal entre $X$ e $Y$, es decir, podemos aproximar $Y =aX+b$, donde $a$ y $b$ son la pendiente y la ordenada al origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV0TUTcCU4XE"
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(-1,1,n) + 0.25*np.random.normal(size = n)\n",
    "y = 4.5*x + 0.25*np.random.normal(size = n)\n",
    "\n",
    "# Graficamos\n",
    "plt.scatter(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpN-9JFmU4XM"
   },
   "source": [
    "La covarianza nos da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEzzOeFtU4XR"
   },
   "outputs": [],
   "source": [
    "cov = np.sum((x - x.mean())*(y - y.mean()))/x.size\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofbVUp7xU4Xa"
   },
   "outputs": [],
   "source": [
    "corr = cov/(x.std()*y.std())\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O19qjolU4Xi"
   },
   "source": [
    "Ahora, en cambio, el valor es cercano a uno, indicando una relación lineal creciente entre ambas variables.\n",
    "\n",
    "**Probar** cambiando la pendiente de la función lineal (el número que multiplica a `x` en `y = ...`) y mirar qué pasa. ¿Qué pasa si la pendiente es negativa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjgjstKaU4Xm"
   },
   "source": [
    "#### Conclusiones\n",
    "\n",
    "1. La covarianza es una medida de la variación conjunta de dos variables. Pero tiene un problema: depende de la escala.\n",
    "2. Para \"deshacernos\" de la escala, definimos la correlación, que es simplemente la covarianza dividida por el producto de la desviación estándar de cada variable. **Para pensar:** ¿por qué la desviación estándar está asociada a la escala de una variable?\n",
    "3. La correlación es un valor entre -1 y 1. La correlación toma un valor cercano a uno cuando hay una relación lineal creciente entre las variables, cero cuando no hay relación y -1 cuando hay una relación lineal decreciente.\n",
    "4. Esta correlación tiene un nombre particular: **Correlación de Pearson**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piVs0Av1U4Xp"
   },
   "source": [
    "### 2.2 Covarianza y Correlación con NumPy\n",
    "\n",
    "**Esta sección es opcional**\n",
    "\n",
    "NumPy ya tiene incorporadas funciones que calculan la covarianza y la correlación entre dos variables. La única diferencia es que, en lugar de devolver un único valor, devuelve cuatro valores, que corresponden a la covarianza/correlación entre $X$ con $X$, $X$ con $Y$, $Y$ con $X$, e $Y$ con $Y$. ¿Por qué, en la correlación, algunos valores son exactamente uno (1.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frlmIIkKU4Xr"
   },
   "outputs": [],
   "source": [
    "np.cov([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWJOKo6sU4Xz"
   },
   "outputs": [],
   "source": [
    "np.corrcoef([x,y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyrooOHbU4X8"
   },
   "source": [
    "### 2.3 Relación No-Lineal entre variables\n",
    "\n",
    "**Esta sección es opcional, pero recomendamos leerla**\n",
    "\n",
    "¿Qué ocurre cuando la relación no es lineal entre las variables? Veámoslo con un ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW2lL_d8U4X-"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x = np.linspace(-5,5,n) + 0.25*np.random.normal(size = n)\n",
    "y = x**2 + 0.25*np.random.normal(size = n)\n",
    "\n",
    "# Graficamos\n",
    "plt.scatter(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0f8gozSU4YF"
   },
   "source": [
    "La covarianza nos da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyOWwrbQU4YH"
   },
   "outputs": [],
   "source": [
    "cov = np.sum((x - x.mean())*(y - y.mean()))/x.size\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_90NldnwU4YP"
   },
   "outputs": [],
   "source": [
    "corr = cov/(x.std()*y.std())\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XiFp1CZU4YX"
   },
   "source": [
    "Notar que la correlación de un valor alrededor de cero, indicando que no hay una correlación entre ambas variables. Pero esto NO indica que no hay una *relación* entre esas variables, solamente nos dice que no es lineal. Por eso es muy importante graficar.\n",
    "\n",
    "**Probar** cambiando la relación matemática entre `x` e `y` y mirar qué pasa.\n",
    "\n",
    "Para tratar con relaciones no lineal entre variables, existen otros tipos de correlaciones. La que vimos se llama **Correlación de Pearson**, que es la más famosa. Pero también existen otras, Spearman y Kendall, que son muy útiles cuando existe una relación no lineal entre variables.\n",
    "\n",
    "### 3. Correlación en Pandas\n",
    "\n",
    "Probablemente ya estés un poco mareado/a con tantos términos, conceptos y líneas de código. Si no entendiste del todo lo anterior, no te preocupes. Vamos a ver cómo lo aplicamos en un conjunto de datos. ¡Verás que es muy sencillo!\n",
    "\n",
    "Para eso, volvemos a usar el Iris Dataset del encuentro anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwu9X-67U4Ya"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSWYv0_WU4Yk"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('DS_Bitácora_04_Iris.csv')\n",
    "data.drop(columns = 'Id', inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hpR90jUU4Yr"
   },
   "source": [
    "Para obtener las correlaciones entre las distintas variables, simplemente tenemos que hacer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j24K4utyU4Yw"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ePNNkIzU4Y3"
   },
   "source": [
    "**Para responder**: ¿Cuáles variables están correlacionadas entre sí?¿Por qué los elementos de la diagonal son exactamente uno (1.0)?\n",
    "\n",
    "Dentro de dos encuentros veremos una forma más eficiente de visualizar esta información, ¡pero ya puedes aplicarla!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Bitácora_05_Probabilidad.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
